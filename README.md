# Joint-Relation Transformer for Multi-Person Motion Prediction
**Abstract**: Multi-person motion prediction is a challenging problem due to the dependency of motion on both individual past movements and interactions with other people. Transformer-based methods have shown promising results on this task, but they miss the explicit relation representation between joints, such as skeleton structure and pairwise distance, which is crucial for accurate interaction modeling. In this paper, we propose the Joint-Relation Transformer, which utilizes relation information to enhance interaction modeling and improve future motion prediction. Our relation information contains the relative distance and the intra-/inter-person physical constraints. To fuse relation and joint information, we design a novel joint-relation fusion layer with relation-aware attention to update both features. Additionally, we supervise the relation information by forecasting future distance. Experimental results on four multi-person motion prediction datasets demonstrate that our proposed method achieves state-of-the-art or comparable performance. 

Code is coming soon.

## Installation

## Pretrained Model

## Acknowledgement

## Citation
